{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbaa638b-964d-4558-ae9d-70ad44651f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The geckodriver version (0.33.0) detected in PATH at c:\\Users\\ROBERT\\3D Objects\\git hub\\selenium\\geckodriver.exe might not be compatible with the detected firefox version (122.0.1.8801); currently, geckodriver 0.34.0 is recommended for firefox 122.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    },
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m content \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m     15\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[1;32m---> 16\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(content, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml5lib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://app.alt.xyz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m links \u001b[38;5;241m=\u001b[39m [a[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcss-dcq7s5\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\ROBERT\\anaconda3\\Lib\\site-packages\\bs4\\__init__.py:250\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[0;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features))\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + \"\"\n",
    "options = Options()\n",
    "options.headless = True  # Running browser in headless mode\n",
    "geckodriver_path = \"geckodriver.exe\"\n",
    "driver = webdriver.Firefox(options=options)\n",
    "url = \"https://app.alt.xyz/browse/liquid-auctions?sortBy=highest_alt_value_first \"\n",
    "driver.get(url)\n",
    "content = driver.page_source\n",
    "driver.quit()\n",
    "soup = BeautifulSoup(content, 'html5lib')\n",
    "base_url = 'https://app.alt.xyz'\n",
    "links = [a[\"href\"] for a in soup.find_all('a', class_=\"css-dcq7s5\")]\n",
    "\n",
    "cards_n_player_number = [span.text for span in soup.find_all('span', class_=\"MuiTypography-root MuiTypography-vegaBody2 MuiTypography-noWrap css-1iu657u\")]\n",
    "card = cards_n_player_number[::2]\n",
    "player_n_number = cards_n_player_number[1::2]\n",
    "\n",
    "grade = [span.text for span in soup.find_all('span', class_=\"MuiTypography-root MuiTypography-vegaBody2 css-1e0sb4z\")]\n",
    "grade = [item for item in grade if item != 'No options.']\n",
    "\n",
    "prices = [span.text for span in soup.find_all('span', class_=\"MuiTypography-root MuiTypography-vegaH7 css-yrl21b\")]\n",
    "auction_data = []\n",
    "for i in range(len(prices)):\n",
    "    auction_dict = {}\n",
    "    auction_dict['link'] = base_url + links[i]\n",
    "    auction_dict['card'] = card[i]\n",
    "    auction_dict['player'] = player_n_number[i].split('#')[0]\n",
    "    if len(player_n_number[i].split('#')) > 1:\n",
    "        auction_dict['card_number'] = player_n_number[i].split('#')[1]\n",
    "    auction_dict['grade'] = grade[i]\n",
    "    auction_data.append(auction_dict)\n",
    "df_auction = pd.DataFrame(auction_data)\n",
    "df_auction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003dd8cd-c5d6-4ec6-940d-f5c3d9a2063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.FirefoxOptions()\n",
    "options.headless = True\n",
    "\n",
    "stats_list = []\n",
    "\n",
    "for url in df_auction['link']:\n",
    "    with webdriver.Firefox(options=options) as driver:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "\n",
    "            # Get the default div's content\n",
    "            default_div = driver.find_element(By.CSS_SELECTOR, '.MuiGrid-grid-sm-9')\n",
    "            default_content = default_div.get_attribute('outerHTML')\n",
    "\n",
    "            # Click the \"View All\" button to load the sidebar\n",
    "            view_all_button = driver.find_element(By.CSS_SELECTOR, 'button.MuiButtonBase-root:nth-child(3)')\n",
    "            view_all_button.click()\n",
    "\n",
    "            # Wait for the sidebar's specific div to be visible\n",
    "            wait = WebDriverWait(driver, 2)  # Wait for up to 2 seconds\n",
    "            sidebar_div = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \".css-nltf5e > div:nth-child(3)\")))\n",
    "\n",
    "            # Get the HTML content of the div\n",
    "            sidebar_content = sidebar_div.get_attribute('outerHTML')\n",
    "\n",
    "            # Create Beautiful Soup objects from the contents\n",
    "            soup_default = BeautifulSoup(default_content, 'html5lib')\n",
    "            soup_sidebar = BeautifulSoup(sidebar_content, 'html5lib')\n",
    "\n",
    "            # Logic to process the soups\n",
    "            divs = soup_sidebar.find_all('div', class_=\"css-vxna0y\")\n",
    "\n",
    "            best_offer_text = [span.text for span in soup_sidebar.find_all('span', class_=\"MuiTypography-root MuiTypography-vegaSubtitle2 css-1gcetpq\")]\n",
    "            offer_price = [span.text.split('$')[1].replace(',','') for span in soup_sidebar.find_all('span', class_=\"MuiTypography-root MuiTypography-vegaSubtitle2 css-16tlq5a\")]\n",
    "            img_source = [div.find('img')['alt'] for div in divs]\n",
    "            dates = [span.text for span in soup_sidebar.find_all('span', class_=\"MuiTypography-root MuiTypography-vegaBody3 css-11ntl8z\")]\n",
    "            offers_data = []\n",
    "            for i in range(len(offer_price)):\n",
    "                offers_dict = {}\n",
    "                offers_dict['best_offer_text'] = best_offer_text[i]\n",
    "                offers_dict['offer_price'] = offer_price[i]\n",
    "                offers_dict['img_source'] = img_source[i]\n",
    "                offers_dict['dates'] = dates[i]\n",
    "                offers_data.append(offers_dict)\n",
    "\n",
    "            df_price = pd.DataFrame(offers_data)\n",
    "\n",
    "            df_price['offer_price'] = df_price['offer_price'].astype('int')\n",
    "            df_price['dates'] = pd.to_datetime(df_price['dates'])\n",
    "            \n",
    "            # Only include sales within the past year. \n",
    "            df_price = df_price[df_price['dates'].dt.year==2022]\n",
    "            \n",
    "            df_stats = {}\n",
    "\n",
    "            df_stats['min_price'] = 0.0\n",
    "            df_stats['max_price'] = 0.0\n",
    "            df_stats['mean_price'] = 0.0\n",
    "            df_stats['median_price'] = 0.0\n",
    "\n",
    "            # If there are more than 3 sales on eBay in the past year, use ONLY the ebay sales\n",
    "            if len(df_price[df_price['img_source']=='eBay']) > 3:\n",
    "                df_price = df_price[df_price['img_source']=='eBay']\n",
    "                df_stats['min_price'] = df_price['offer_price'].min()\n",
    "                df_stats['max_price'] = df_price['offer_price'].max()\n",
    "                df_stats['mean_price'] = df_price['offer_price'].mean()\n",
    "                df_stats['median_price'] = df_price['offer_price'].median()\n",
    "            else:\n",
    "                df_stats['min_price'] = df_price['offer_price'].min()\n",
    "                df_stats['max_price'] = df_price['offer_price'].max()\n",
    "                df_stats['mean_price'] = df_price['offer_price'].mean()\n",
    "                df_stats['median_price'] = df_price['offer_price'].median()\n",
    "\n",
    "\n",
    "            df_stats = pd.DataFrame(df_stats,index=[0])\n",
    "\n",
    "            df_stats['breakeven_price'] = df_stats['mean_price'].apply(lambda x: x*0.62 if x < 2500 else 1560+(x-2500)*0.7)\n",
    "            df_stats['make_10%_price'] = df_stats['mean_price'].apply(lambda x: x*0.56 if x < 2500 else 1400+(x-2500)*0.63)\n",
    "            df_stats['dollar_under'] = df_stats['breakeven_price'] - (15600 / 1.2)\n",
    "            df_stats['percent_under'] = 15600 / (1.2 * df_stats['breakeven_price'])\n",
    "            df_stats['url'] = url\n",
    "            \n",
    "            stats_dict = dict(df_stats)\n",
    "            \n",
    "            stats_dict['min_fixed_price'] = min(int(num) for num in [span.text.split('$')[1].replace(',','') for span in soup_default.find_all('span', class_=\"MuiTypography-root MuiTypography-vegaSubtitle2 css-w9sxkt\")])\n",
    "            \n",
    "            stats_list.append(stats_dict)\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "df_stats = pd.DataFrame(stats_list)\n",
    "df_auction = df_auction.merge(df_stats,left_on='link',right_on=['url'])\n",
    "df_auction.drop(columns=['url'],inplace=True)\n",
    "df_auction.to_csv('scraped_results_complete.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bebeb59-fdab-4f18-bcde-dbb19a525429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
